{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([2.5, 3.5, 5.6, 2.2, 6.9, 9.6],dtype=float)\n",
    "y = np.array([0,0,1,0,1,1],dtype=float)\n",
    "\n",
    "alpha = 0.001\n",
    "m = len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Cost: 0.6931, theta: [0.         0.00115833]\n",
      "Iteration 10: Cost: 0.6819, theta: [-6.43486058e-05  1.11703012e-02]\n",
      "Iteration 20: Cost: 0.6711, theta: [-0.00026418  0.02147099]\n",
      "Iteration 30: Cost: 0.6620, theta: [-0.00058815  0.03097525]\n",
      "Iteration 40: Cost: 0.6541, theta: [-0.00102569  0.03975156]\n",
      "Iteration 50: Cost: 0.6475, theta: [-0.00156707  0.04786326]\n",
      "Iteration 60: Cost: 0.6417, theta: [-0.00220332  0.05536849]\n",
      "Iteration 70: Cost: 0.6368, theta: [-0.00292631  0.06232033]\n",
      "Iteration 80: Cost: 0.6325, theta: [-0.00372861  0.068767  ]\n",
      "Iteration 90: Cost: 0.6288, theta: [-0.00460348  0.0747522 ]\n",
      "Iteration 100: Cost: 0.6256, theta: [-0.00554481  0.08031551]\n",
      "\n",
      "Final theta: [-0.0055  0.0803]\n"
     ]
    }
   ],
   "source": [
    "#Batch Gradient Descent\n",
    "theta = np.array([0,0],dtype=float)\n",
    "X_bias = np.hstack((np.ones((m,1)),X.reshape(-1,1)))\n",
    "\n",
    "def cost_func(predictions, y):\n",
    "    return (-1/m) * np.sum(y * np.log(predictions) + (1-y) * np.log(1-predictions))\n",
    "\n",
    "def hypothesis(X,theta):\n",
    "    return 1 / (1 + np.exp(-(X @ theta)))\n",
    "\n",
    "iterations = 100\n",
    "for i in range(1,iterations+1):\n",
    "    predictions = hypothesis(X_bias,theta)\n",
    "    errors = predictions - y\n",
    "    gradient = 1/m * (errors @ X_bias)\n",
    "    theta -= alpha * gradient\n",
    "\n",
    "    if (i%10==0 or i == 1):\n",
    "        print(f\"Iteration {i}: Cost: {cost_func(predictions,y):.4f}, theta: {theta}\")\n",
    "\n",
    "print(\"\\nFinal theta:\", np.round(theta,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10: Cost: 0.6404, theta: [-0.00201116  0.05641829]\n",
      "Iteration 20: Cost: 0.6194, theta: [-0.00730865  0.09193569]\n",
      "Iteration 30: Cost: 0.6098, theta: [-0.0145458   0.11522996]\n",
      "Iteration 40: Cost: 0.6046, theta: [-0.02296517  0.13110946]\n",
      "Iteration 50: Cost: 0.6012, theta: [-0.03212752  0.14231465]\n",
      "Iteration 60: Cost: 0.5987, theta: [-0.04176632  0.15048359]\n",
      "Iteration 70: Cost: 0.5965, theta: [-0.05171356  0.15663705]\n",
      "Iteration 80: Cost: 0.5944, theta: [-0.06186018  0.16143169]\n",
      "Iteration 90: Cost: 0.5924, theta: [-0.0721339   0.16529993]\n",
      "Iteration 100: Cost: 0.5905, theta: [-0.08248609  0.16853142]\n",
      "\n",
      "Final theta: [-0.0825  0.1685]\n"
     ]
    }
   ],
   "source": [
    "#Stochastic Gradient Descent\n",
    "theta = np.array([0,0],dtype=float)\n",
    "X_bias = np.hstack((np.ones((m,1)),X.reshape(-1,1)))\n",
    "\n",
    "def hypothesis(X,theta):\n",
    "    return 1/(1+ np.exp(-(X @ theta)))\n",
    "\n",
    "def cost_func(predictions,y):\n",
    "    return (-1/m) * np.sum(y*np.log(predictions) + (1-y)*np.log(1-predictions))\n",
    "\n",
    "iterations = 100\n",
    "for i in range(1,iterations+1):\n",
    "    for j in range(m):\n",
    "        x_j = X_bias[j,:].reshape(1,-1)\n",
    "        y_j = y[j]\n",
    "        predictions_j = hypothesis(x_j,theta)\n",
    "        errors_j = predictions_j - y_j\n",
    "        gradient_j = errors_j * x_j #no need for 1/m\n",
    "        theta -= alpha * gradient_j.flatten()\n",
    "\n",
    "    predictions = hypothesis(X_bias,theta)  \n",
    "    cost = cost_func(predictions,y)\n",
    "    \n",
    "    if (i%10==0):\n",
    "        print(f\"Iteration {i}: Cost: {cost_func(predictions,y):.4f}, theta: {theta}\")\n",
    "\n",
    "print(\"\\nFinal theta:\", np.round(theta,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0.99752738 0.99966465 0.99999497 0.99550373 0.99999963 1.        ]\n",
      "Errors: [ 9.97527377e-01  9.99664650e-01 -5.03043030e-06  9.95503727e-01\n",
      " -3.73629798e-07 -1.68752989e-09]\n",
      "Gradient: [0.49878172 1.36378703]\n",
      "Regularized Gradient: [0.49878172 4.69712036]\n",
      "Hessian: [[0.00121387 0.00286962]\n",
      " [0.00286962 0.00689369]]\n",
      "Regularized Hessian: [[1.21386823e-03 2.86961572e-03]\n",
      " [2.86961572e-03 1.00068937e+01]]\n",
      "New theta: [-409.85904114    1.98153478]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1, 2.5],\n",
    "              [1, 3.5],\n",
    "              [1, 5.6],\n",
    "              [1, 2.2],\n",
    "              [1, 6.9],\n",
    "              [1, 9.6]\n",
    "              ])\n",
    "y = np.array([0,0,1,0,1,1])\n",
    "theta = np.array([1,2])\n",
    "l = 10\n",
    "\n",
    "predictions = 1 / (1 + np.exp(-(X@theta)))\n",
    "print(\"Predictions:\",predictions)\n",
    "\n",
    "errors = predictions - y\n",
    "print(\"Errors:\",errors)\n",
    "\n",
    "gradient = 1/6 * X.T @ errors\n",
    "print(\"Gradient:\",gradient)\n",
    "\n",
    "reg_term = (l / 6) * theta  \n",
    "reg_term[0] = 0  # Ensure theta_0 is not regularized\n",
    "regularized_gradient = gradient + reg_term\n",
    "print(\"Regularized Gradient:\", regularized_gradient)\n",
    "\n",
    "hessian = 1/6 * X.T @ np.diag(predictions * (1-predictions)) @ X\n",
    "print(\"Hessian:\",hessian)\n",
    "\n",
    "reg_matrix = np.eye(X.shape[1])\n",
    "reg_matrix[0, 0] = 0  # Ensure theta_0 is not regularized\n",
    "regularized_hessian = hessian + l * reg_matrix\n",
    "print(\"Regularized Hessian:\", regularized_hessian)\n",
    "\n",
    "theta = theta - np.linalg.inv(regularized_hessian) @ gradient\n",
    "print(\"New theta:\",theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
